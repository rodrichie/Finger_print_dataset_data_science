{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iibzkonszCQe"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ku6M40Iwm3qy",
        "outputId": "a6f5babe-8c8c-4242-c156-d235c1f4982e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-08-09 12:54:46.430417: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-08-09 12:54:47.844223: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/alvin/anaconda3/envs/asr/lib/python3.9/site-packages/cv2/../../lib64:\n",
            "2023-08-09 12:54:47.844327: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/alvin/anaconda3/envs/asr/lib/python3.9/site-packages/cv2/../../lib64:\n",
            "2023-08-09 12:54:47.844338: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import re\n",
        "import cv2 as cv\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import resnet50, inception_v3, densenet\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import Model, layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import compute_class_weight\n",
        "from skimage.feature import hessian_matrix, hessian_matrix_eigvals\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXzh0J0nyRnc"
      },
      "source": [
        "# Custom Metrics by Nabasa Rodrick"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSZvCZKdbhXo"
      },
      "source": [
        "## F1 Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AX5gWE9eGYW6"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "\n",
        "# Instantiate precision and recall metric objects\n",
        "p = Precision(thresholds=0)\n",
        "r = Recall(thresholds=0)\n",
        "\n",
        "def f1_score(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Function that calculates and returns\n",
        "  f1_score using Precision and Recall\n",
        "  \"\"\"\n",
        "\n",
        "  def precision(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Function that calculates and returns precision\n",
        "    \"\"\"\n",
        "    p.update_state(y_true, y_pred)\n",
        "    return p.result()\n",
        "\n",
        "  def recall(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Function that calculates and returns recall\n",
        "    \"\"\"\n",
        "    r.update_state(y_true, y_pred)\n",
        "    return r.result()\n",
        "\n",
        "  precision = precision(y_true, y_pred)\n",
        "  recall = recall(y_true, y_pred)\n",
        "\n",
        "  result = tf.math.multiply_no_nan(\n",
        "      tf.constant(2, tf.float32),\n",
        "      tf.math.divide_no_nan(\n",
        "          tf.math.multiply_no_nan(\n",
        "              precision,\n",
        "              recall\n",
        "          ),\n",
        "          tf.math.add(\n",
        "              precision,\n",
        "              recall\n",
        "          )\n",
        "      )\n",
        "  )\n",
        "\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODpJubSJPEuS"
      },
      "source": [
        "# Augmentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXiTcYk10BVc"
      },
      "outputs": [],
      "source": [
        "def random_rotation(img):\n",
        "  img_shape = img.shape\n",
        "  img = tf.squeeze(img)\n",
        "\n",
        "  img = img.numpy().astype(np.uint8)\n",
        "  img = cv.cvtColor(img, cv.COLOR_RGB2GRAY)\n",
        "\n",
        "  degree = np.random.randint(-15,15,1)[0]\n",
        "\n",
        "  rows,cols = img.shape\n",
        "  rotation_matrix = cv.getRotationMatrix2D(((cols-1)/2.0,(rows-1)/2.0), degree, 1)\n",
        "  img = cv.warpAffine(img, rotation_matrix, (cols,rows))\n",
        "\n",
        "  img = cv.cvtColor(img, cv.COLOR_GRAY2RGB)\n",
        "  img = tf.convert_to_tensor(img, dtype=tf.float32)\n",
        "\n",
        "  img = tf.expand_dims(img, 0)\n",
        "  img.set_shape(img_shape)\n",
        "\n",
        "  return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cNl_XonZmLV"
      },
      "outputs": [],
      "source": [
        "def hist_eq(img):\n",
        "  img_shape = img.shape\n",
        "  img = tf.squeeze(img)\n",
        "\n",
        "  img = img.numpy().astype(np.uint8)\n",
        "  img = cv.cvtColor(img, cv.COLOR_RGB2GRAY)\n",
        "\n",
        "  contrast = np.random.uniform(1.0,2.0)\n",
        "  clahe = cv.createCLAHE(clipLimit=contrast, tileGridSize=(16,16))\n",
        "  img = clahe.apply(img)\n",
        "\n",
        "  img = cv.cvtColor(img, cv.COLOR_GRAY2RGB)\n",
        "  img = tf.convert_to_tensor(img, dtype=tf.float32)\n",
        "\n",
        "  img = tf.expand_dims(img, 0)\n",
        "  img.set_shape(img_shape)\n",
        "\n",
        "  return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0u6pX9dkvtjD"
      },
      "outputs": [],
      "source": [
        "# Smoothing to remove noise\n",
        "def smoothing(img):\n",
        "  img_shape = img.shape\n",
        "  img = tf.squeeze(img)\n",
        "\n",
        "  img = img.numpy().astype(np.uint8)\n",
        "\n",
        "  img = cv.GaussianBlur(img,(3,3),0)\n",
        "\n",
        "  img = tf.convert_to_tensor(img, dtype=tf.float32)\n",
        "\n",
        "  img = tf.expand_dims(img, 0)\n",
        "  img.set_shape(img_shape)\n",
        "\n",
        "  return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mM_JHFBuKy6v"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def augmentation(img):\n",
        "  img = tf.py_function(hist_eq, [img], tf.float32)\n",
        "  img = tf.py_function(random_rotation, [img], tf.float32)\n",
        "\n",
        "  img = tf.reshape(img, (1,96,103,channels))\n",
        "\n",
        "  return img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLJiQ_Z1btNS"
      },
      "source": [
        "# Global Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4K2shHCdzhp9"
      },
      "outputs": [],
      "source": [
        "#Define global variables\n",
        "channels = 4\n",
        "image_size = (96,103)\n",
        "image_shape = image_size + (channels,)\n",
        "batch_size = 64\n",
        "\n",
        "rng = tf.random.Generator.from_seed(42, alg='philox')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data prep by Aheebwa Steven"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dir =r'C:\\Users\\HP\\Desktop\\final_project_recess\\Group_F_machine_learning\\Recess_Project_Template\\resources\\datasets\\fingerprint_datasets'\n",
        "classes = ['Altered-Easy', 'Altered-Hard', 'Altered-Medium', 'Real']\n",
        "classes_map = dict(zip(classes,range(len(classes))))\n",
        "class_dict = {key:len(glob.glob(f'{dir}/{key}/*.BMP')) for key in classes}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot class distribution\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "sns.barplot(y=list(class_dict.values()), x=list(class_dict.keys()), color='g')\n",
        "plt.title('Distribution of Classes')\n",
        "plt.ylabel('Class counts')\n",
        "plt.xlabel('Classes')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(dir,\n",
        "                                                       validation_split=0.2,\n",
        "                                                       subset=\"training\",\n",
        "                                                       seed=42,\n",
        "                                                       image_size=image_size,\n",
        "                                                       batch_size=batch_size,\n",
        "                                                       label_mode='categorical',\n",
        "                                                       labels='inferred'\n",
        "                                                       )\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(dir,\n",
        "                                                     validation_split=0.2,\n",
        "                                                     subset=\"validation\",\n",
        "                                                     seed=42,\n",
        "                                                     image_size=image_size,\n",
        "                                                     batch_size=batch_size,\n",
        "                                                     label_mode='categorical',\n",
        "                                                     labels='inferred'\n",
        "                                                     )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_names = train_ds.class_names\n",
        "num_classes = len(class_names)\n",
        "print(class_names)\n",
        "print(num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_class_weights():\n",
        "  total = sum(class_dict.values())\n",
        "  class_weights = {}\n",
        "\n",
        "  for class_name, class_count in class_dict.items():\n",
        "    class_weights[class_names.index(class_name)] = (1 / class_count) * (total / num_classes)\n",
        "\n",
        "  return class_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_weights = get_class_weights()\n",
        "class_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize(original, augmented):\n",
        "\n",
        "  def show(ax, image, title):\n",
        "    ax.set_title(title)\n",
        "    ax.imshow(image)\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "  fig = plt.figure(figsize=(9, 9))\n",
        "\n",
        "  axs = fig.subplots(1, 2)\n",
        "\n",
        "  show(axs[0], original, 'original')\n",
        "  show(axs[1], augmented, 'augmented')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample = list(train_ds.take(1))[0][0][:1]\n",
        "sample_aug = augmentation(sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample = sample[0].numpy().astype(np.uint8)\n",
        "sample_aug = sample_aug[0].numpy().astype(np.uint8)\n",
        "\n",
        "visualize(sample, sample_aug)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Joining the augmentated dataset to the original train dataset\n",
        "train_ds_aug = train_ds.rebatch(1).map(lambda x, y: (augmentation(x), y)).rebatch(batch_size)\n",
        "train_ds = train_ds.concatenate(train_ds_aug).rebatch(1).shuffle(buffer_size=2048).rebatch(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalising data\n",
        "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
        "\n",
        "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# To optimise the pipeline\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_ds.element_spec"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "iibzkonszCQe",
        "FXzh0J0nyRnc",
        "eSZvCZKdbhXo"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
